# healthfair

## 目的

本项目的目的是能够自动提取出数据集中存在偏见的属性，并且自动能够为这些属性打上等级

## 原有方法

原来的方法只能自动地提取出偏见较大的保护属性，采用的策略是首先训练自定的模型（例如逻辑回归模型）进行预测，使用训练好的模型的预测结果来进行不公平性指标的计算（针对每一个特征），选出每个不公平性指标下不公平性最大的20个特征，然后将这些特征取交集，最终能够选择出不公平性最显著的几个特征。这样便提取出偏见较大的保护属性。

但是这样的方法存在一些问题，比如，这个交集有可能是空集，并且这个过程不够智能。

## 计划改进的方法

计划改进的方法依然需要训练自定的模型（例如逻辑回归模型）进行预测，并且使用训练好的模型的预测结果计算得出存在偏见的属性，这个过程需要模仿[Mitigating Calibration Bias Without Fixed Attribute Grouping for Improved Fairness in Medical Imaging Analysis](https://arxiv.org/pdf/2307.01738.pdf)中两阶段训练方法的第一个阶段

目前的一些基本的想法就是：

1. 我希望根据模型的预测结果来对不确定性进行分类，类似于上文提到的K聚类分析，对于不确定性比较高的几类，我分析究竟是那些属性导致这几类样本的不确定性高，由此确定偏见较大的保护属性。

2. 我刚刚也调研了一种变分自编码器（VAE）

3. 变分自编码器（VAE）是一种深度生成模型，它可以从数据中学习一个潜在变量的概率分布，并从该分布中采样新的数据点。😊

   变分自编码器的基本思想是，给定一个输入数据x，我们假设存在一个潜在变量z，它可以表示x的一些特征或属性。我们想要学习一个潜在变量的后验分布p(z|x)，即给定x时z的条件概率。然而，这个后验分布往往是很难计算或近似的，因为它涉及到一个不可积分的边缘似然p(x)。

   为了解决这个问题，变分自编码器引入了一个变分分布q(z|x)，它是一个可以用神经网络参数化的简单分布，比如高斯分布。我们希望用q(z|x)来近似p(z|x)，并最小化两者之间的差异，即KL散度。同时，我们也希望用另一个神经网络来表示生成模型p(x|z)，即给定z时x的条件概率。我们希望最大化这个条件概率的期望，即重构误差。

   综合起来，变分自编码器的目标函数是：

   $$L(x) = E_{q(z|x)}[\log p(x|z)] - KL(q(z|x)||p(z))$$

   其中，p(z)是一个先验分布，通常假设为标准正态分布。

   为了优化这个目标函数，我们需要用到重参数化技巧，即将采样过程转化为一个可导的函数。具体来说，我们假设$q(z|x)$是一个均值为$μ$，方差为$σ^2$的高斯分布，则我们可以从标准正态分布中采样一个$ϵ$，然后令$z=μ+σϵ$。这样，我们就可以通过反向传播来更新神经网络的参数。

   变分自编码器可以用来生成新的数据，只需要从先验分布p(z)中采样一个z，然后通过生成模型p(x|z)得到对应的x。变分自编码器也可以用来学习数据的低维表征，即潜在变量z。

   目前该思路还在调研当中，我可能会参考下面的资料

   - [一文理解变分自编码器（VAE） - 知乎](https://zhuanlan.zhihu.com/p/64485020)
   - [VAE变分自编码机详解——原理篇 - 知乎](https://zhuanlan.zhihu.com/p/108262170)
   - [理解变分自编码器（VAE） - 知乎](https://zhuanlan.zhihu.com/p/519448634)
   - [变分自编码器（Variational auto-encoder, VAE）理解及教程](https://blog.csdn.net/weixin_43876801/article/details/103654186)

   
